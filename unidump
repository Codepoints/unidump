#!/usr/bin/env python3
"""
hexdump(1) for Unicode data
"""

import argparse
import doctest
import fileinput
import sys
import unicodedata


__version__ = '1.1'

default_lineformat = '{byte:>7}    {repr}    {data}\n'

description = '''A Unicode codepoint dump.

Think  of it as  hexdump(1)  for Unicode.  The command analyses  the input  and
prints then  three columns:  the raw byte count of the first codepoint  in this
row,  codepoints in their  hex notation,  and finally the raw  input characters
with control and whitespace replaced by a dot.

Invalid byte sequences are represented with an  ‚ÄúX‚Äù  and with the hex value en-
closed in question marks, e.g., ‚Äú?F5?‚Äù.

You can pipe in data from stdin, select several files at once, or mix all those
input methods together.'''

epilog = '''Examples:

* Basic usage with stdin:

      echo -n 'ABCDEFGHIJKLMNOP' | unidump -n 4
            0    0041 0042 0043 0044    ABCD
            4    0045 0046 0047 0048    EFGH
            8    0049 004A 004B 004C    IJKL
           12    004D 004E 004F 0050    MNOP

* Dump the code points translated from another encoding:

      unidump -c latin-1 some-legacy-file

* Dump many files at the same time:

      unidump foo-*.txt

* Control characters and whitespace are safely rendered:

      echo -n -e '\\x01' | unidump -n 1
           0    0001    .

* Finally learn what your favorite Emoji is composed of:

      ( echo -n -e '\\xf0\\x9f\\xa7\\x9d\\xf0\\x9f\\x8f\\xbd\\xe2' ; \\
        echo -n -e '\\x80\\x8d\\xe2\\x99\\x82\\xef\\xb8\\x8f' ; ) | \\
      unidump -n 5
           0    1F9DD 1F3FD 200D 2642 FE0F    .üèΩ.‚ôÇÔ∏è

  See <http://emojipedia.org/man-elf-medium-skin-tone/>. The ‚Äúelf‚Äù emoji is
  replaced with a dot, because the current version of Python‚Äôs unicodedata
  doesn‚Äôt know of this character yet.

* Use it like strings(1):

      unidump -e '{data}' some-file.bin

  This will replace all unknown bytes from the input file with ‚ÄúX‚Äù and all
  control and whitespace characters with ‚Äú.‚Äù.

* Only print the code points of the input:

      unidump -e '{repr}'$'\\n' -n 1 some-file.txt

  This results in a stream of codepoints in hex notation, each on a new line,
  without byte counter or rendering of actual data. You can use this to count
  the total amount of characters (as opposed to raw bytes) in a file, if you
  pipe it through `wc -l`.
'''


def sanitize_char(char):
    """replace char with a dot, if it's a control or whitespace char

    Close to what hexdump does, but Unicode-aware. Characters that unicodedata
    is not aware of will also be replaced with a dot.

    >>> sanitize_char('A')
    'A'
    >>> sanitize_char('\U0001F678')
    '\U0001F678'
    >>> sanitize_char(' ')
    '.'
    >>> sanitize_char('\x01')
    '.'
    >>> # un-set Unicode character, should have category "Cn"
    >>> sanitize_char('\U000D0000')
    '.'
    >>> sanitize_char('a1')
    Traceback (most recent call last):
        ...
    TypeError: category() argument must be a unicode character, not str
    """
    category = unicodedata.category(char)
    if category[0] in ('C', 'Z'):
        return '.'
    return char


def print_line(line, linelength, lineformat=None):
    """
    >>> print_line([0, ['00A0', '00B0', '00C0'], 'ABC'], 4)
          0    00A0 00B0 00C0         ABC\n
    >>> print_line([12, ['00A0', '1F678', '00C0'], 'A\U0001F678C'], 4)
         12    00A0 1F678 00C0        A\U0001F678C\n
    """
    sys.stdout.write((lineformat or default_lineformat).format(
        byte=line[0],
        repr=' '.join(line[1]).ljust(linelength*5-1),
        data=line[2]
    ))


def fill_and_print_output(current_line, linelength, byteoffset, representation,
                          char, lineformat=None):
    """
    >>> current_line = [0, [], '']
    >>> current_line = fill_and_print_output(current_line, 2, 0, '0076', 'v')
    >>> current_line == [0, ['0076'], 'v']
    True
    >>> current_line = fill_and_print_output(current_line, 2, 1, '0076', 'v')
    >>> current_line = fill_and_print_output(current_line, 2, 2, '0077', 'w')
          0    0076 0076    vv\n
    >>> current_line == [1, ['0077'], 'w']
    True
    """
    if len(current_line[1]) >= linelength:
        print_line(current_line, linelength, lineformat)
        current_line = [byteoffset - 1, [representation], char]
    else:
        current_line[1].append(representation)
        current_line[2] += char

    return current_line


def unidump(input, linelength=16, encoding='utf-8', lineformat=None):
    """take a list of bytes and print their Unicode codepoints

    >>> import io
    >>> unidump(io.BytesIO(b'\\x01\\xF0\\x9F\\x99\\xB8ABC'), 4)
          0    0001 1F678 0041 0042    .\U0001F678AB
          7    0043                   C
    >>> unidump(io.BytesIO(b'\\xD7'), 4)
          0    ?D7?                   X
    >>> unidump(io.BytesIO(b'\\xD7'), 4, encoding='latin1')
          0    00D7                   \u00D7
    """

    byteoffset = 0
    bytebuffer = b''
    current_line = [0, [], '']

    byte = input.read(1)
    while byte:
        byteoffset += 1
        bytebuffer += byte

        try:
            char = bytebuffer.decode(encoding)
        except UnicodeDecodeError:
            next_byte = input.read(1)
            if not next_byte or len(bytebuffer) >= 4:
                for i, x in enumerate(bytebuffer):
                    current_line = (
                        fill_and_print_output(current_line, linelength,
                                              byteoffset - 3 + i,
                                              '?{:02X}?'.format(x), 'X',
                                              lineformat)
                    )
                bytebuffer = b''
            byte = next_byte
            continue
        else:
            current_line = (
                fill_and_print_output(current_line, linelength, byteoffset,
                                      '{:04X}'.format(ord(char)),
                                      sanitize_char(char), lineformat)
            )

        bytebuffer = b''
        byte = input.read(1)

    print_line(current_line, linelength, lineformat)


def main():
    parser = argparse.ArgumentParser(
        description=description,
        epilog=epilog,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument('files', nargs='*', metavar='FILE', default=('-',),
                        help='input files. Use `-\' or keep empty for stdin.')
    parser.add_argument('-n', '--length', type=int, default=16,
                        help='format output using this much input characters. '
                        'Default is %(default)s characters.')
    parser.add_argument('-c', '--encoding', type=str, default='utf-8',
                        metavar='ENC',
                        help='interpret input in this encoding. Default is '
                        '%(default)s. You can choose any encoding that Python '
                        'supports, e.g. ‚Äúlatin-1‚Äù.')
    parser.add_argument('-e', '--format', type=str, default=default_lineformat,
                        help='specify a custom format in Python‚Äôs {} notation.'
                        ' Default is ‚Äú%(default)s‚Äù.')
    parser.add_argument('-v', '--version', action='version',
                        version='%(prog)s {}'.format(__version__))

    a = parser.parse_args()

    try:
        for filename in a.files:
            if filename == '-':
                infile = sys.stdin.buffer
            else:
                try:
                    infile = open(filename, 'rb')
                except FileNotFoundError:
                    sys.stdout.flush()
                    sys.stderr.write('File {} not found.\n'.format(filename))
                    continue
            unidump(infile, a.length, a.encoding, a.format)
    except KeyboardInterrupt:
        sys.stdout.flush()
        # sys.stderr.write('Interrupted\n')
        sys.exit(1)
    else:
        sys.exit(0)


if __name__ == '__main__':
    if '--self-test' in sys.argv:
        doctest.testmod(verbose=('--verbose' in sys.argv))
    else:
        main()
